---
title: "About"
layout: textlay
excerpt: "About"
sitemap: false
permalink: /about/
---

# About4
\
&nbsp;
![]({{ site.url }}{{ site.baseurl }}/images/aboutpic/tmu_logo.png){: style="width: 150px; float: left; margin: 0px  10px"}
I am an Assistant Professor in the Department of Mechanical and Industrial Engineering at Toronto Metropolitan University (formerly Ryerson) in Toronto, Canada. My research at Ryerson focuses on robotics, SLAM, focal-plane sensor-processor arrays (FPSP), and deep learning.

\
&nbsp;

![]({{ site.url }}{{ site.baseurl }}/images/aboutpic/icl_logo.png){: style="width: 150px; float: left; margin: 0px  10px"}
![]({{ site.url }}{{ site.baseurl }}/images/aboutpic/dyson_logo.png){: style="width: 70px; float: left; margin: 0px  10px"}
From July 2018 to July 2019, I was a Dyson Research Fellow at Imperial College London, working with Prof. Andrew Davison and Prof. Stefan Leutenegger on Semantic SLAM. Previously I was a Research Associate at Robot Vision Group. I worked on the PAMELA project, with Prof. Andrew Davison and Prof. Paul Kelly. At Imperial College London, I work on many interesting and cutting-edge robotics and vision algorithms and devices including focal-plane sensor-processor arrays (FPSP), deep learning, and active vision.


\
&nbsp;


![]({{ site.url }}{{ site.baseurl }}/images/aboutpic/2g_logo.png){: style="width: 150px; float: left; margin: 0px  10px"}
In 2015, I was working at 2G Robotics (now Voyis Imaging Inc.) on underwater robotics and perception. Developing machine vision algorithms in underwater environments is a very challenging problem due to nonlinear light refraction in water-glass-air interfaces of the camera housing. I was actively involved in the following projects:


**Underwater Stereo Vision**: By using stereoscopic vision in underwater, we can make 3D models of underwater structures and wreckages. Building 3D models in real-time will allow underwater robots to navigate autonomously. In this project, I performed various tasks such as designing a stereoscopic system, stereo camera calibration, extracting depth from stereo images, performing visual odometry, and 3D point cloud mapping. The mapping application was developed with C++ and OpenCV under Linux.


**Omnidirectional Perception**: In this project, a unique omnidirectional catadioptric camera system combined with underwater laser was developed. The goal of the project is to build 3D models of unknown environments (implementation in C++/Linux).


\
&nbsp;

